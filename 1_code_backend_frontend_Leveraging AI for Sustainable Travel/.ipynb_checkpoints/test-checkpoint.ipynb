{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e162f68a-ea6d-424d-b1b2-2731e0c846e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tianlimin/anaconda3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from text2vec import SentenceModel\n",
    "from flask import Flask\n",
    "from flask import render_template\n",
    "from flask import request\n",
    "from qdrant_client import QdrantClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93fabbe5-d40b-4275-afaa-6cfa2234205d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/tianlimin/vector based model/server\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#os.chdir('/root/ChatBot/QA')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ea336b9-f590-4670-a110-b3203e6ca39c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-02-04 09:20:05.127\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36mtext2vec.sentence_model\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m80\u001b[0m - \u001b[34m\u001b[1mUse device: cpu\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 加载向量化模型\n",
    "t2v_model = SentenceModel(\"/Users/tianlimin/LLM/model-parameter/text2vec_cmed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31ec8c2c-d949-4c24-9ee2-b5d99a091a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入数据库key\n",
    "with open('key.txt','r') as f:\n",
    "    key = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c01f7af-7506-4248-994d-b86c3ce05e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文本向量化\n",
    "def to_embeddings(text):\n",
    "    sentence_embeddings = t2v_model.encode(text)\n",
    "    return sentence_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4e6648-8ad9-4fb1-a1e3-c9c366f73c4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load model\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers import StoppingCriteria, StoppingCriteriaList, TextIteratorStreamer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/Users/tianlimin/LLM/model-parameter/TinyLlama-1.1B-intermediate-step-1431k-3T\")\n",
    "model = AutoModel.from_pretrained(\"/Users/tianlimin/LLM/model-parameter/TinyLlama-1.1B-intermediate-step-1431k-3T\").half().to('mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e769e94-073a-41ac-ac44-976bdf4013bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_glm(text,hsitory=[]):\n",
    "    response, history = model.chat(tokenizer, text, history=hsitory)\n",
    "    return response,history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505e8642-9915-473f-bee9-cae594ee96ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ask_glm('What about the headache?')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5a38f5-3502-4e90-806b-f71c33661077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt(question, answers):\n",
    "    q = '请分析用户故事,根据提示的答案写出用户故事的分数和评价，测试\\n' \n",
    "    for index, answer in enumerate(answers):\n",
    "        q += str(index + 1) + '. ' + str(answer['text']) + '\\n'\n",
    "    q = q+\"问题：%s || 答案：\" % question\n",
    "\n",
    "    return q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b6b16c-2abc-4f7b-9508-0c985a0f13fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(text):\n",
    "    client = QdrantClient(\n",
    "        url=\"https://9759a1d6-6cf2-4049-bd61-a5cb09ee44f3.us-east4-0.gcp.cloud.qdrant.io:6333\", \n",
    "        api_key=key,\n",
    "    )\n",
    "    collection_name = \"questions\"\n",
    "    \n",
    "    vector = to_embeddings(text)\n",
    "    \"\"\"\n",
    "    取搜索结果的前三个，如果想要更多的搜索结果，可以把limit设置为更大的值\n",
    "    \"\"\"\n",
    "    search_result = client.search(\n",
    "        collection_name=collection_name,\n",
    "        query_vector=vector.tolist(),\n",
    "        limit=1,\n",
    "        search_params={\"exact\": False, \"hnsw_ef\": 128}\n",
    "    )\n",
    "    answers = []\n",
    " \n",
    "    \"\"\"\n",
    "    每个匹配的相关摘要只取了前300个字符，如果想要更多的相关摘要，可以把这里的300改为更大的值\n",
    "    \"\"\"\n",
    "    for result in search_result:\n",
    "        if len(result.payload[\"text\"]) > 1000:\n",
    "            summary = result.payload[\"text\"][:1000]\n",
    "        else:\n",
    "            summary = result.payload[\"text\"]\n",
    "        answers.append({ \"text\": summary})\n",
    "    promptMessage=prompt(text, answers)\n",
    "    print(promptMessage)\n",
    "    response,history =  ask_glm(promptMessage)\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6812523b-0e9d-41cd-99b4-ff9a376039a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query('\"作为顾客，我想将产品添加到购物车，以便稍后购买\"。')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c46ea7-8856-4a10-a829-f575223fa955",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
